<!DOCTYPE html>
<html lang="en"><head>
	<meta charset="utf-8">
    <link rel="stylesheet" href="https://nr-linux.com/css/syntax.css">
    <link rel="shortcut icon", href="/sources/images/NR.ico">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?940d62eb74c20aae5d1fde8c0eca604d";
          var s = document.getElementsByTagName("script")[0]; 
          s.parentNode.insertBefore(hm, s);
        })();
    </script>
</head>
<title>NR Linux</title>
  <link href="/css/style.css" rel="stylesheet">
  <body>
  	<div class="container"> 
		<div class="sidebar">
			<div class="sidebar-item sidebar-header">
	<div class='sidebar-brand'>
		<a href="https://nr-linux.com/index.html">NR Linux</a>
	</div>
    
	<p class="lead">Nrush's tech blogs. Focus on linux kernel.</p>
    <p>
        <hr>
        | <a href="https://github.com/nrusher">github</a> |
          <a href="https://gitee.com/nrush">gitee</a> | 
          <a href="https://nr-linux.com/bio.html">bio</a> |
          <a href="https://nr-linux.com/index.html">home</a> |
        <hr>
    </p>
</div>

<!--search-->
<br/>
<!-- HTML elements for search -->
<input type="text" id="search-input" placeholder="search here"  style="min-width: 240px;"/>
<ul id="results-container"></ul>

<!-- script pointing to jekyll-search.js -->
<script src="https://nr-linux.com/js/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    json: '/search.json',
    searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a></li>',
    noResultsText: '',
    limit: 5,
    fuzzy: false
  })
</script>
<br/>

<div class="sidebar-item sidebar-nav">
  	<ul class="nav">
			<li class="nav-title">
                <a href="https://nr-linux.com/categories" style="color: white;"> Categories </a>
            </li>
	    
	    <li>
            <a href="https://nr-linux.com/jekyll.html">
				<span class="name">jekyll</span>
				<span class="badge">2</span>
	    	</a>
 		  </li>
	    
	    <li>
            <a href="https://nr-linux.com/linux-tool.html">
				<span class="name">linux-tool</span>
				<span class="badge">1</span>
	    	</a>
 		  </li>
	    
	    <li>
            <a href="https://nr-linux.com/performance.html">
				<span class="name">performance</span>
				<span class="badge">1</span>
	    	</a>
 		  </li>
	    
	    <li>
            <a href="https://nr-linux.com/architecture.html">
				<span class="name">architecture</span>
				<span class="badge">1</span>
	    	</a>
 		  </li>
	    
	    <li>
            <a href="https://nr-linux.com/others.html">
				<span class="name">others</span>
				<span class="badge">1</span>
	    	</a>
 		  </li>
	    
	  </ul>
</div>

<div class="sidebar-item sidebar-nav">
    <ul class="nav">
        <li class="nav-title">
          <a href="https://nr-linux.com/links" style="color: white;"> links </a>
        </li>
        <li><a href="https://www.brendangregg.com/">brendangregg</a></li>
        <li><a href="https://lwn.net/">lwn</a></li>
        <li><a href="https://nr-linux.com/Tool-Box">tool box</a></li>
    </ul>
</div>

<div class="sidebar-item sidebar-nav">
  <p class="nav-title">NOTE</p>
  <p class="lead"> Enjoy it.</p>
</div>

<br>
<div class="sidebar-item sidebar-nav">
  <p class="nav-title">RECENT</p>
  <p class="lead"> Enjoy it.</p>
</div>

<div class="sidebar-item sidebar-footer">
	<p>Powered by <a href="https://github.com/jekyll/jekyll">Jekyll</a></p>
</div>

		</div>
		<div class="content">
            <div class="paper">
                <hr style="height:5px;border:none;border-top:5px double;"/>
			    <center><strong><font size="6">Computer Architecture A Quantitative Approach</font></strong></center>

<ul id="markdown-toc">
  <li><a href="#classes-of-parallelism-and-parallel-architectures" id="markdown-toc-classes-of-parallelism-and-parallel-architectures">Classes of Parallelism and Parallel Architectures</a></li>
  <li><a href="#13-defining-computer-architecture" id="markdown-toc-13-defining-computer-architecture">1.3 Defining Computer Architecture</a></li>
  <li><a href="#14-trends-in-technology" id="markdown-toc-14-trends-in-technology">1.4 Trends in Technology</a></li>
  <li><a href="#15-trends-in-power-and-energy-in-integrated-circuits" id="markdown-toc-15-trends-in-power-and-energy-in-integrated-circuits">1.5 Trends in Power and Energy in Integrated Circuits</a></li>
  <li><a href="#16-trends-in-cost" id="markdown-toc-16-trends-in-cost">1.6 Trends in Cost</a></li>
  <li><a href="#18-measuring-reporting-and-summarizing-performance" id="markdown-toc-18-measuring-reporting-and-summarizing-performance">1.8 Measuring, Reporting, and Summarizing Performance</a></li>
  <li><a href="#reference" id="markdown-toc-reference">Reference</a></li>
</ul>

<h3 id="classes-of-parallelism-and-parallel-architectures">Classes of Parallelism and Parallel Architectures</h3>
<p>parallelism in applications:</p>
<ol>
  <li>
    <p>Data-Level Parallelism (DLP) arises because there are many data items that
can be operated on at the same time</p>
  </li>
  <li>
    <p>Task-Level Parallelism (TLP) arises because tasks of work are created that
can operate independently and largely in parallel.</p>
  </li>
</ol>

<p>Computer hardware in turn can exploit these two kinds of application parallelism
in four major ways:</p>

<ol>
  <li>Instruction-Level Parallelism exploits data-level parallelism at modest levels
with compiler help using ideas like pipelining and at medium levels using
ideas like speculative execution.</li>
  <li>Vector Architectures and Graphic Processor Units (GPUs) exploit data-level
parallelism by applying a single instruction to a collection of data in parallel.</li>
  <li>Thread-Level Parallelism exploits either data-level parallelism or task-level
parallelism in a tightly coupled hardware model that allows for interaction
among parallel threads.</li>
  <li>Request-Level Parallelism exploits parallelism among largely decoupled
tasks specified by the programmer or the operating system.</li>
</ol>

<p>He looked at the parallelism in the
instruction and data streams called for by the instructions at the most con-
strained component of the multiprocessor, and placed all computers into one of
four categories:</p>

<ol>
  <li>Single instruction stream, single data stream (SISD)—This category is the
uniprocessor. The programmer thinks of it as the standard sequential com-
puter, but it can exploit instruction-level parallelism. Chapter 3 covers SISD
architectures that use ILP techniques such as superscalar and speculative exe-
cution.</li>
  <li>Single instruction stream, multiple data streams (SIMD)—The same
instruction is executed by multiple processors using different data streams.
SIMD computers exploit data-level parallelism by applying the same
operations to multiple items of data in parallel. Each processor has its own
data memory (hence the MD of SIMD), but there is a single instruction
memory and control processor, which fetches and dispatches instructions.
Chapter 4 covers DLP and three different architectures that exploit it:
vector architectures, multimedia extensions to standard instruction sets,
and GPUs.</li>
  <li>Multiple instruction streams, single data stream (MISD)—No commercial
multiprocessor of this type has been built to date, but it rounds out this simple
classification.</li>
  <li>Multiple instruction streams, multiple data streams (MIMD)—Each proces-
sor fetches its own instructions and operates on its own data, and it targets
task-level parallelism. In general, MIMD is more flexible than SIMD and
thus more generally applicable, but it is inherently more expensive than
SIMD. For example, MIMD computers can also exploit data-level parallel-
ism, although the overhead is likely to be higher than would be seen in an
SIMD computer. This overhead means that grain size must be sufficiently
large to exploit the parallelism efficiently. Chapter 5 covers tightly coupled
MIMD architectures, which exploit thread-level parallelism since multiple
cooperating threads operate in parallel. Chapter 6 covers loosely coupled
MIMD architectures—specifically, clusters and warehouse-scale comput-
ers—that exploit request-level parallelism, where many independent tasks
can proceed in parallel naturally with little need for communication or
synchronization.</li>
</ol>

<h2 id="13-defining-computer-architecture">1.3 Defining Computer Architecture</h2>

<p>Determine what attributes are important for a new computer, then design a computer to maximize
performance and energy efficiency while staying within cost, power, and avail-
ability constraints</p>

<p>instruction set architecture (ISA)</p>

<h2 id="14-trends-in-technology">1.4 Trends in Technology</h2>

<p>bandwidth or throughput is the total amount of work done in a given time.</p>

<p>latency or response time is the time between the start and the completion of an event</p>

<p>A simple rule of thumb is that bandwidth grows by at least the square of the improvement in latency.</p>

<h2 id="15-trends-in-power-and-energy-in-integrated-circuits">1.5 Trends in Power and Energy in Integrated Circuits</h2>

<p>Today, power is the biggest challenge facing the computer designer for nearly
every class of computer. First, power must be brought in and distributed around
the chip, and modern microprocessors use hundreds of pins and multiple inter-
connect layers just for power and ground. Second, power is dissipated as heat and
must be removed.</p>

\[E_{dynamic 0-&gt;1} \propto 1/2 \times C \times V^{2}\]

\[P_{dynamic} \propto 1/2 \times C \times V^{2} \times F\]

\[P_{static} \propto I_{static} V\]

<h2 id="16-trends-in-cost">1.6 Trends in Cost</h2>

<p>die越小，晶圆越大越便宜</p>

<h2 id="18-measuring-reporting-and-summarizing-performance">1.8 Measuring, Reporting, and Summarizing Performance</h2>

<h2 id="reference">Reference</h2>

            </div>
		</div>
	</div>
  </body>
</html>